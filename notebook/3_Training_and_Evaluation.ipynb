{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9894ee54-5842-4aff-9db7-1f30771ec9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# put yolov7_pitch.yaml to cfg/training folder\n",
    "# pitch_data.yaml to data folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989be28a-e8a7-4d31-a70b-076600ea1d3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f3d8baa8-22d8-4bac-a98e-405fe87b5217",
   "metadata": {},
   "source": [
    "## training is launched via command line with command:\n",
    "### python train.py --workers 1 --device 0 --batch-size 8 --epochs 100 --img 640 640 --data data/pitch_data.yaml --hyp data/hyp.scratch.custom.yaml --cfg cfg/training/yolov7_pitch.yaml --name yolov7_pitch_0 --weights yolov7.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae78ba8-49a8-4bab-b466-8b8acf9bbfba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shutil\n",
    "from PIL import Image, ImageDraw\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d956de07-b6cb-46c9-b5c3-cf2ed53f532c",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a160b6fa-51fc-46c5-ac23-0ac4b080d84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccfc8528-2e64-41d1-89e6-8ea1c2ad393c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results from 1. training are located at:\n",
    "# ./runs/train/yolov7_pitch_04\n",
    "# best weights named best_0 are placed in ./"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e562204-7f47-4855-96b6-7a893f89506e",
   "metadata": {},
   "source": [
    "## running inference on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90fb584-c3f0-4239-8505-f20394472e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567c7b2a-49a0-43f2-9eee-5e4f4303680a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# put your path to main directory here\n",
    "os.chdir('C:\\\\Users\\\\Kossa\\\\Desktop\\\\respo_vision\\\\yolov7-pitch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6080c9dd-f01a-4995-9ebc-626ea909d1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14dafe27-5e1a-4a2b-9bbc-6547053ee2a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!python detect.py --weights best_0.pt --conf 0.5 --img-size 640 --source inference/images --save-txt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81f4cff-4495-4115-8ef9-05dbce3996e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('C:\\\\Users\\\\Kossa\\\\Desktop\\\\respo_vision\\\\yolov7-pitch\\\\notebook')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012b9791-0d5f-40e2-b736-2833c3e9fbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729fbc0b-73a0-4b3e-b820-2ac7fc4c2949",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_val_df = pd.read_csv('vis_val_df_0.csv').drop('Unnamed: 0', axis = 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566c8e79-ffe5-4ccf-aca3-4735c78684e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df = pd.read_csv('val_df_0.csv').drop('Unnamed: 0', axis = 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c0431a-e1f7-4ea9-b2dd-30f5f4899e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7b8001-f8be-4dc8-9abb-1d48a91509a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df.isna().any().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e21e2e-5b23-4bae-81e4-88d07406ec07",
   "metadata": {},
   "outputs": [],
   "source": [
    "path2 = 'C:\\\\Users\\\\Kossa\\\\Desktop\\\\respo_vision\\\\yolov7-pitch'\n",
    "#yolov7-pitch\\runs\\detect\\exp\\labels <---- location of results labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f8547e-6633-44a9-82fa-ec2c7e66032c",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_vis_classes_val = ['a37d3123f9202186d20a7765ec2c0a.jpg',\n",
    " '934a5454a825420abe74ace1cbe2b0.jpg',\n",
    " 'fffe2a9e755bf705c79753bf09b7f1.jpg',\n",
    " '73aec0a4b73935433808780a577f3c.jpg',\n",
    " '32e27114c613d5a58cc95b3f6262ab.jpg',\n",
    " '2e031ce6ec3a9b7a45d70bcdf7618e.jpg',\n",
    " '03a17019ec63792e8316633d50d109.jpg',\n",
    " '3e6cbfd6d83cc24393092a74522062.jpg',\n",
    " '07b7b54074da586b6c0effd7f5ba9e.jpg',\n",
    " '5ad1adfad421cb8bd6ced67369cd38.jpg',\n",
    " '370bcfad2192293a0a25daf431d7d4.jpg',\n",
    " 'ae1ba09379c7277fa88c5cff12c398.jpg',\n",
    " '7db8876376346a856b26cf799e97dd.jpg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42afe6e3-3eae-4560-b711-6328fad92881",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_vis_classes_val = [item[:-4] for item in no_vis_classes_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f638be-9827-4fec-b435-0975521bb0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_vis_classes_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95ef27a-3ca2-4898-addd-5f2d4db0ba32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# yolo format - object-class-id> <x> <y> <width> <height>\n",
    "#filling val_df with predictions - x_pred and y_pred\n",
    "\n",
    "infer_data = {}\n",
    "for filename in val_df['image_path'].unique():\n",
    "\n",
    "    # print(df[1]['x'])\n",
    "    source_path = filename\n",
    "    filename = filename.split('/')[-1][:-4]\n",
    "\n",
    "    if filename in no_vis_classes_val:\n",
    "        print(filename)\n",
    "        continue\n",
    "    # print(filename, '\\n')\n",
    "    temp = []\n",
    "    duplicate_classes = [] #checking for duplciate classes in output\n",
    "\n",
    "    with open(f'{path2}\\\\runs\\\\detect\\\\exp\\\\labels\\\\{filename}.txt', 'r') as file:\n",
    "        lines = file.readlines()\n",
    "        for line in lines:\n",
    "            # print(line)\n",
    "            data = line.split(' ')\n",
    "            if data[0] not in temp:\n",
    "                temp.append(data[0])\n",
    "            else:\n",
    "                duplicate_classes.append(data[0])\n",
    "\n",
    "            val_df.loc[(val_df['image_path'] == source_path) & (val_df['kid'] == int(data[0])), \n",
    "                        ['x_pred', 'y_pred']] = int(float(data[1])*1920), int(float(data[2])*1080)\n",
    "                                                                                                                        \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812aa672-554a-4fa3-9b78-2b08a8438cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52cabe65-9ab0-47be-9646-2ee6ae86f534",
   "metadata": {},
   "outputs": [],
   "source": [
    "# That is very good. the model did not predict the same class twice for one image. \n",
    "# It is quite obvious, since training data never contained 2 classes at once, but it was good to confirm this\n",
    "# That simplifies the analysis and I can just input predictions to existing df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b884fc70-ac63-4691-b007-fbffcab8e002",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# checking filenames with confusions\n",
    "\n",
    "# <object-class-id> <x> <y> <width> <height>\n",
    "# label_pad = 50 #px\n",
    "confused_list = []\n",
    "for filename in vis_val_df['image_path'].unique():\n",
    "    # print(df[1]['x'])\n",
    "    source_path = filename\n",
    "    filename = filename.split('/')[-1][:-4]\n",
    "    # print(filename, '\\n')\n",
    "\n",
    "    duplicate_classes = [] #checking for duplciate classes in output\n",
    "\n",
    "    # print(f'************************* {filename} ***********************')\n",
    "    \n",
    "    temp = []\n",
    "    with open(f'{path2}\\\\runs\\\\detect\\\\exp\\\\labels\\\\{filename}.txt', 'r') as file:\n",
    "        lines = file.readlines()\n",
    "        for line in lines:\n",
    "            data = line.split(' ')\n",
    "            temp.append(int(data[0]))\n",
    "        # print(sorted(temp))\n",
    "\n",
    "    temp2 = []    \n",
    "    with open(f'{path2}\\\\data\\\\val\\\\labels\\\\{filename}.txt', 'r') as file:\n",
    "        lines = file.readlines()\n",
    "        for line in lines:\n",
    "            data = line.split(' ')\n",
    "            temp2.append(int(data[0]))\n",
    "        # print(sorted(temp))\n",
    "\n",
    "    if sorted(temp) != sorted(temp2):\n",
    "        print(filename)\n",
    "        print(sorted(temp))\n",
    "        print(sorted(temp2))\n",
    "        confused_list.append(filename)\n",
    "                \n",
    "\n",
    "\n",
    "\n",
    "                                                                                                                        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76110da8-bf94-4566-ba0b-80261b879457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for plotting\n",
    "\n",
    "class_name_to_id_mapping = {str(i):i for i in range(40)}\n",
    "\n",
    "class_id_to_name_mapping = dict(zip(class_name_to_id_mapping.values(), class_name_to_id_mapping.keys()))\n",
    "\n",
    "def plot_bounding_box(image, annotation_list):\n",
    "    annotations = np.array(annotation_list)\n",
    "    w, h = image.size\n",
    "    \n",
    "    plotted_image = ImageDraw.Draw(image)\n",
    "\n",
    "    transformed_annotations = np.copy(annotations)\n",
    "    transformed_annotations[:,[1,3]] = annotations[:,[1,3]] * w\n",
    "    transformed_annotations[:,[2,4]] = annotations[:,[2,4]] * h \n",
    "    \n",
    "    transformed_annotations[:,1] = transformed_annotations[:,1] - (transformed_annotations[:,3] / 2)\n",
    "    transformed_annotations[:,2] = transformed_annotations[:,2] - (transformed_annotations[:,4] / 2)\n",
    "    transformed_annotations[:,3] = transformed_annotations[:,1] + transformed_annotations[:,3]\n",
    "    transformed_annotations[:,4] = transformed_annotations[:,2] + transformed_annotations[:,4]\n",
    "    \n",
    "    for ann in transformed_annotations:\n",
    "        obj_cls, x0, y0, x1, y1 = ann\n",
    "        plotted_image.rectangle(((x0,y0), (x1,y1)))\n",
    "        \n",
    "        plotted_image.text((x0, y0 - 10), class_id_to_name_mapping[(int(obj_cls))])\n",
    "    \n",
    "    plt.imshow(np.array(image))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee497e95-0f6b-4215-aad3-3b016b290383",
   "metadata": {},
   "outputs": [],
   "source": [
    "path2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2e4210-7346-454f-becc-235692e659c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# filling val_df with predictions for confused preds\n",
    "for filename in confused_list:\n",
    "\n",
    "    temp = []\n",
    "    temp2 = []\n",
    "\n",
    "    print(filename)\n",
    "\n",
    "    img_path = f'{path2}\\\\data\\\\val\\\\images\\\\{filename}.jpg'\n",
    "    labels_path = f'{path2}\\\\data\\\\val\\\\labels\\\\{filename}.txt'\n",
    "    \n",
    "    img_path_infer = f'{path2}\\\\runs\\\\detect\\\\exp\\\\{filename}.jpg'\n",
    "    labels_path_infer = f'{path2}\\\\runs\\\\detect\\\\exp\\\\labels\\\\{filename}.txt'\n",
    "    \n",
    "    image = Image.open(img_path)\n",
    "    with open(labels_path, 'r') as file:\n",
    "        labels = file.readlines()\n",
    "\n",
    "    for line in labels:\n",
    "        data = line.split(' ')\n",
    "        temp.append(int(data[0]))\n",
    "\n",
    "    print(sorted(temp))\n",
    "    \n",
    "    annotation_file = labels_path\n",
    "    with open(annotation_file, \"r\") as file:\n",
    "        annotation_list = file.read().split(\"\\n\")[:-1]\n",
    "        annotation_list = [x.split(\" \") for x in annotation_list]\n",
    "        annotation_list = [[float(y) for y in x ] for x in annotation_list]\n",
    "        \n",
    "    plot_bounding_box(image, annotation_list)\n",
    "\n",
    "    image = Image.open(img_path_infer)\n",
    "    with open(labels_path_infer, 'r') as file:\n",
    "        labels = file.readlines()\n",
    "\n",
    "    for line in labels:\n",
    "        data = line.split(' ')\n",
    "        temp2.append(int(data[0]))\n",
    "\n",
    "    print(sorted(temp2))\n",
    "    \n",
    "    annotation_file = labels_path\n",
    "    with open(annotation_file, \"r\") as file:\n",
    "        annotation_list = file.read().split(\"\\n\")[:-1]\n",
    "        annotation_list = [x.split(\" \") for x in annotation_list]\n",
    "        annotation_list = [[float(y) for y in x ] for x in annotation_list]\n",
    "        \n",
    "    plot_bounding_box(image, annotation_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c6863b-a7bb-4807-b536-4f05c32b2e06",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Some EDA and checks for confused files\n",
    "confused_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0698a345-f919-4400-8bad-bcf2ca4f6886",
   "metadata": {},
   "outputs": [],
   "source": [
    "confused_list_path = [f'images/train/{filename}.jpg' for filename in confused_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0c00af-9ad0-4890-b10b-d35fcbec744d",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df.head(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a3ea52-aa20-452f-8a32-8a3c3d3f54e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df.fillna(0, inplace = True)\n",
    "val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47f9299-76a3-43a8-82bc-b5d77762e9cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 100)\n",
    "val_df[val_df['image_path'].isin(confused_list_path)].head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dcfcc23-7a8f-4c75-ac7b-b081644655ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df.loc[(val_df['x_pred'] > 0) | (val_df['y_pred'] > 0)  ,'vis_pred'] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e7d862-2c3d-4c8b-84c8-b2ce455c327b",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df.fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b06e86-5ef5-4f01-b348-7ea81cd7cf58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# introducing correct location - corr_loc column\n",
    "\n",
    "corr_loc = []\n",
    "for row in val_df.itertuples():\n",
    "    if row.vis == row.vis_pred == 2 and abs(row.x - row.x_pred) < 50 and abs(row.y - row.y_pred) < 50:\n",
    "        corr_loc.append(1)\n",
    "    elif row.vis == row.vis_pred == 0:\n",
    "        corr_loc.append(1)\n",
    "    else:\n",
    "        corr_loc.append(0)\n",
    "val_df['corr_loc'] = corr_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c2532d-e95c-4cfa-beda-84c263d923d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c160bb3-53c9-4e59-ad3a-07f2358afd49",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "val_df[val_df['corr_loc'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776814bd-e0a5-4369-9c56-70b9e1ec6187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# comapring corr_loc with files with confusions\n",
    "\n",
    "print(len(val_df[val_df['corr_loc'] == 0]['image_path'].unique()))\n",
    "\n",
    "len(confused_list)\n",
    "# val_df[val_df['corr_loc'] == 0]['image_path'].unique()\n",
    "# almost agrees with the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55fff10d-146b-41bb-ad3b-7703b00e784d",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_confused = [item for item in val_df[val_df['corr_loc'] == 0]['image_path'].unique() if item not in confused_list_path]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02689b1-4652-41a2-b5fb-ac3e09336ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_confused"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fff6621-9521-405b-986f-85784e2afbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_confused_2 = [item for item in confused_list_path if item not in  val_df[val_df['corr_loc'] == 0]['image_path'].unique()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d29d265-0d60-451e-ad72-9ee0c788879b",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_confused_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf527a68-f177-4160-b088-d60bd8fae03f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# classes are correct, but distance is too high\n",
    "val_df[val_df['image_path'].isin(diff_confused)].head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c42b72-e986-466f-b7c5-265e91ae9ada",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#that one is actually correct\n",
    "val_df[val_df['image_path'].isin(diff_confused_2)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e51d23-2dfb-4d1e-b16e-9a5abad05ef0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "val_df[val_df['image_path'].isin(diff_confused)].head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f309d3-7ac7-42e2-8be6-3ac5f2c8e8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# determining prediction of kid. - 0 if it fits nowhere\n",
    "\n",
    "conf_pred_kid = []\n",
    "for row in val_df.itertuples():\n",
    "    if not row.corr_loc:\n",
    "        _flag = True\n",
    "        temp_df = val_df[val_df['image_path'] == row.image_path]\n",
    "        for row2 in val_df.itertuples():\n",
    "            if abs(row.x_pred - row2.x) < 50 and abs(row.y_pred - row.y) < 50:\n",
    "                conf_pred_kid.append(row2.kid)\n",
    "                _flag = False\n",
    "                break\n",
    "        if _flag:\n",
    "            conf_pred_kid.append(0)\n",
    "    else:\n",
    "        conf_pred_kid.append(row.kid)\n",
    "\n",
    "val_df['pred_kid'] = conf_pred_kid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756228d2-5445-4926-8bb2-a0653ab40d59",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "val_df[val_df['image_path'].isin(confused_list_path)].head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6baa9c-43e1-4b70-8a0e-03ff446ed049",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df[val_df['kid']!=val_df['pred_kid']]#.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88aa69f5-7eaa-4db6-8f0a-b2915c119943",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df[(val_df['kid']!=val_df['pred_kid']) & val_df['pred_kid']]#.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe643b5-58c4-4771-a8bb-1395d8b6c569",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "val_df[val_df['image_path'].isin(confused_list_path)].head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04bfe380-c1ff-4aa3-b2f2-6add84dd919a",
   "metadata": {},
   "source": [
    "## calculating metrices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07194b0b-4213-4565-a93f-e68bf536f3fe",
   "metadata": {},
   "source": [
    "## Avg for all classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c1bd28-6864-4b92-8f3f-0aa04d6ecf51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# time to remove it\n",
    "fake_kid = [24,36,37,38]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1666b4d5-6b84-43b5-a435-95711b1178f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df = val_df[~val_df['kid'].isin(fake_kid)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd0b6c7-cade-4bfd-8934-e8f10b3623f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7ed204-c853-4581-8083-f553f330fd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df.loc[ (val_df['corr_loc'] == 1) & (val_df['vis'] == 2) & (val_df['vis_pred'] == 2) ,'outcome'] = 'TP'\n",
    "val_df.loc[ (val_df['corr_loc'] == 1) & (val_df['vis'] == 0) & (val_df['vis_pred'] == 0) ,'outcome'] = 'TN'\n",
    "val_df.loc[ (val_df['corr_loc'] == 0) & (val_df['vis'] == 0) & (val_df['vis_pred'] == 2) ,'outcome'] = 'FP'\n",
    "val_df.loc[ (val_df['corr_loc'] == 0) & (val_df['vis'] == 2) & (val_df['vis_pred'] == 0) ,'outcome'] = 'FN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76398d3f-3207-4eae-a37b-aaddca1ae399",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df.loc[val_df['outcome'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f79e74-ed53-4084-a057-f313890bd393",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0d8eaf-53cb-4b0a-9cf3-8b0fe4de682c",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df.loc[ (val_df['corr_loc'] == 0) & (val_df['vis'] == 2) & (val_df['vis_pred'] == 2) ,'outcome'] = 'CONF'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4796054b-70a2-4105-a967-581572b65893",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f400db2c-f2f3-4d7d-9243-55e640f0df76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if CONT is correct\n",
    "val_df.loc[val_df['outcome'] == 'CONF', ['x', 'y', 'vis', 'kid', 'dataset', 'image_path', 'x_pred', 'y_pred',\n",
    "       'vis_pred', 'corr_loc', 'pred_kid']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1e546f-faa9-4862-b80f-3b4c708d6cb8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "val_df.head(100)#.loc[val_df['outcome'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d82144-dbe2-4988-9ed2-0a8272603fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df = val_df.groupby('outcome').count()\n",
    "grouped_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f06ca29-e54b-46e5-86a7-9da7280b9568",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = (grouped_df.loc['TP', 'x'] + grouped_df.loc['TN', 'x']) / ( grouped_df.loc['FP', 'x'] + grouped_df.loc['FN', 'x'] + grouped_df.loc['TP', 'x'] + grouped_df.loc['TN', 'x'])\n",
    "precision = grouped_df.loc['TP', 'x'] / ( grouped_df.loc['TP', 'x'] + grouped_df.loc['FP', 'x'])\n",
    "recall = grouped_df.loc['TP', 'x'] / ( grouped_df.loc['TP', 'x'] + grouped_df.loc['FN', 'x'])\n",
    "f1 = 2* precision * recall / ( precision + recall )\n",
    "info = recall - 1 + grouped_df.loc['TN', 'x'] / ( grouped_df.loc['TN', 'x'] + grouped_df.loc['FP', 'x'])\n",
    "mark = precision - 1 + grouped_df.loc['TN', 'x'] / ( grouped_df.loc['TN', 'x'] + grouped_df.loc['FN', 'x'])\n",
    "mcc = ((info * mark)**0.5)\n",
    "conf_rate = grouped_df.loc['CONF', 'x'] / ( grouped_df.loc['FP', 'x'] + grouped_df.loc['FN', 'x'] + grouped_df.loc['TP', 'x'])\n",
    "conf_among_mistakes = grouped_df.loc['CONF', 'x'] / ( grouped_df.loc['FP', 'x'] + grouped_df.loc['FN', 'x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ddd9e46-f21c-4396-a1a4-eacd7c4df75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy)\n",
    "print(precision)\n",
    "print(recall)\n",
    "print(f1)\n",
    "print(info)\n",
    "print(mark)\n",
    "print(mcc)\n",
    "print(conf_rate)\n",
    "print(conf_among_mistakes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f6fe82-dd79-47a0-bff7-ff0444f907fb",
   "metadata": {},
   "source": [
    "## per class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f1882f-f852-4467-a287-eb293b0d1209",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_metrics_per_kid = pd.DataFrame()\n",
    "for tup in val_df.groupby('kid'):\n",
    "    df_kid = tup[1]\n",
    "    df_kid = df_kid.groupby('outcome').count()\n",
    "    # print(df_kid)\n",
    "    for key in ['FN', 'FP', 'TN', 'TP', 'CONF']:\n",
    "        if key not in df_kid.index:\n",
    "            df_kid.loc[key, 'x'] = 0\n",
    "    print(df_kid)\n",
    "    accuracy = (df_kid.loc['TP', 'x'] + df_kid.loc['TN', 'x']) / ( df_kid.loc['FP', 'x'] + df_kid.loc['FN', 'x'] + df_kid.loc['TP', 'x'] + df_kid.loc['TN', 'x'])\n",
    "    precision = df_kid.loc['TP', 'x'] / ( df_kid.loc['TP', 'x'] + df_kid.loc['FP', 'x'])\n",
    "    recall = df_kid.loc['TP', 'x'] / ( df_kid.loc['TP', 'x'] + df_kid.loc['FN', 'x'])\n",
    "    f1 = 2* precision * recall / ( precision + recall )\n",
    "    info = recall - 1 + df_kid.loc['TN', 'x'] / ( df_kid.loc['TN', 'x'] + df_kid.loc['FP', 'x'])\n",
    "    mark = precision - 1 + df_kid.loc['TN', 'x'] / ( df_kid.loc['TN', 'x'] + df_kid.loc['FN', 'x'])\n",
    "    mcc = ((info * mark)**0.5)\n",
    "    conf_rate = df_kid.loc['CONF', 'x'] / ( df_kid.loc['FP', 'x'] + df_kid.loc['FN', 'x'] + df_kid.loc['TP', 'x'])\n",
    "    conf_among_mistakes = df_kid.loc['CONF', 'x'] / ( df_kid.loc['FP', 'x'] + df_kid.loc['FN', 'x'])\n",
    "    df_metrics_per_kid.loc[tup[0], ['accuracy', 'precision', 'recall', 'f1', 'informedness', 'markedness', 'MCC', 'CONF_rate', 'CONF_per_F']] = accuracy, precision, recall, f1, info, mark, mcc, conf_rate, conf_among_mistakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964cacc4-f5a8-4be5-b6bc-a38c41f3a387",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics_per_kid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a659d380-4512-4084-9618-5e1fdfb4d10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots()\n",
    "# fig = plt.Figure(fig_size = (8, 16))\n",
    "# ax.barh(df_metrics_per_kid.index, df_metrics_per_kid[['f1', 'MCC']])\n",
    "# ax.barh(df_metrics_per_kid.index, df_metrics_per_kid[])\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "\n",
    "ax = df_metrics_per_kid[['f1', 'MCC']].plot.barh(figsize=(4,8))\n",
    "ax.set_ylabel('Keypoint')\n",
    "ax.set_title('Key metrics per class')\n",
    "# ax.set_yticks(labels=[str(index) for index in df_metrics_per_kid.index])\n",
    "\n",
    "# x.set_ylim(8, 16)\n",
    "\n",
    "plt.show()\n",
    "plt.close()\n",
    "ax = df_metrics_per_kid[['precision', 'recall']].plot.barh(figsize=(4,8), color = ['green','purple'])\n",
    "ax.set_ylabel('Keypoint')\n",
    "ax.set_title('Key metrics per class')\n",
    "# ax.set_yticks(labels=[str(index) for index in df_metrics_per_kid.index])\n",
    "\n",
    "# x.set_ylim(8, 16)\n",
    "\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d72d46-a6ae-4669-97bb-5db3e12a398a",
   "metadata": {},
   "source": [
    "## metrics for class placement precision - MAE and MSE are suitable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76bbd2d-9e52-439d-97bb-9513700e5bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can apporach it in the soft way and in the hard way\n",
    "# soft - we will not penalize model for confusing classes and FP and FN. Therefore we will only calculate AE and SE for TP. TN will be infored for obvious reasons.\n",
    "# medium - we will penalize model for confusing classes - TP and CONF\n",
    "# hard - we will penalize model for everything - FP, FN and CONF classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacf7320-99e9-410f-a77e-c2b83466e0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88df378c-b458-44c5-bf31-192ef785d99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df.loc[val_df['outcome'] == 'TP',  'AEx_soft'] = abs(val_df['x'] - val_df['x_pred'])\n",
    "val_df.loc[val_df['outcome'] == 'TP',  'AEy_soft'] = abs(val_df['y'] - val_df['y_pred'])\n",
    "val_df.loc[(val_df['outcome'] == 'TP') | (val_df['outcome'] == 'CONF'),  'AEx_med'] = abs(val_df['x'] - val_df['x_pred'])\n",
    "val_df.loc[(val_df['outcome'] == 'TP') | (val_df['outcome'] == 'CONF'),  'AEy_med'] = abs(val_df['y'] - val_df['y_pred'])\n",
    "val_df.loc[val_df['outcome'] != 'TN',  'AEx_hard'] = abs(val_df['x'] - val_df['x_pred'])\n",
    "val_df.loc[val_df['outcome'] != 'TN',  'AEy_hard'] = abs(val_df['y'] - val_df['y_pred'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957f9b71-74d4-4c68-a181-82a2880056e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453ad3b8-61c9-4a38-acc2-4a6352e73cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df['AE_soft'] = (val_df['AEx_soft']**2 + val_df['AEy_soft']**2)**0.5\n",
    "val_df['AE_med'] = (val_df['AEx_med']**2 + val_df['AEy_med']**2)**0.5\n",
    "val_df['AE_hard'] = (val_df['AEx_hard']**2 + val_df['AEy_hard']**2)**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2998e347-c473-470d-83c8-8a4124cdf569",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df.loc[val_df['outcome'] == 'TP',  'SEx_soft'] = (val_df['x'] - val_df['x_pred'])**2\n",
    "val_df.loc[val_df['outcome'] == 'TP',  'SEy_soft'] = (val_df['y'] - val_df['y_pred'])**2\n",
    "val_df.loc[(val_df['outcome'] == 'TP') | (val_df['outcome'] == 'CONF'),  'SEx_med'] = (val_df['x'] - val_df['x_pred'])**2\n",
    "val_df.loc[(val_df['outcome'] == 'TP') | (val_df['outcome'] == 'CONF'),  'SEy_med'] = (val_df['y'] - val_df['y_pred'])**2\n",
    "val_df.loc[val_df['outcome'] != 'TN',  'SEx_hard'] = (val_df['x'] - val_df['x_pred'])**2\n",
    "val_df.loc[val_df['outcome'] != 'TN',  'SEy_hard'] = (val_df['y'] - val_df['y_pred'])**2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096ba2e7-e19b-4ca0-a7ba-86d4e23e2682",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df['SE_soft'] = val_df['SEx_soft'] + val_df['AEy_soft']\n",
    "val_df['SE_med'] = val_df['SEx_med'] + val_df['AEy_med']\n",
    "val_df['SE_hard'] = val_df['SEx_hard'] + val_df['AEy_hard']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbb197f-67be-42ed-94ca-1bb0f6dae280",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ecf284-ca2e-48c0-83da-d1119aa9a042",
   "metadata": {},
   "outputs": [],
   "source": [
    "for err in ['AE_soft', 'AE_med', 'AE_hard', 'SE_soft', 'SE_med', 'SE_hard']:\n",
    "    print(f'M{err}: ', val_df[err].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51488a7d-24fd-4dd1-8326-9e97b014980d",
   "metadata": {},
   "source": [
    "## average per class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26815992-912f-4faa-9fe9-02e65a0a36d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for err in ['AE_soft', 'AE_med', 'AE_hard', 'SE_soft', 'SE_med', 'SE_hard']:\n",
    "\n",
    "    print(f'M{err}: ', val_df[err].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54080432-073e-4510-881d-21e8b8338f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics_per_kid_2 = val_df[['kid','AE_soft', 'AE_med', 'AE_hard', 'SE_soft', 'SE_med', 'SE_hard']].groupby('kid').mean()\n",
    "df_metrics_per_kid_2 = df_metrics_per_kid_2.rename(columns={\"AE_soft\": \"MAE_soft\", \"SE_soft\": \"MSE_soft\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a57b94-bc15-4025-b60f-54d0a6f88150",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics_per_kid_2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7592ff-a4bf-4c7a-998a-11c2c5e9d9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots()\n",
    "# fig = plt.Figure(fig_size = (8, 16))\n",
    "# ax.barh(df_metrics_per_kid.index, df_metrics_per_kid[['f1', 'MCC']])\n",
    "# ax.barh(df_metrics_per_kid.index, df_metrics_per_kid[])\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "\n",
    "ax = df_metrics_per_kid_2[['MAE_soft', 'MSE_soft']].plot.barh(figsize=(4,8))\n",
    "ax.set_ylabel('Keypoint')\n",
    "ax.set_title('Key metrics per class')\n",
    "# ax.set_yticks(labels=[str(index) for index in df_metrics_per_kid.index])\n",
    "\n",
    "# x.set_ylim(8, 16)\n",
    "\n",
    "plt.show()\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02fad180-655e-4cc4-be09-8ba71ab864ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9405e3-ddb2-4b16-bd14-c6b738b41b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df[(val_df['kid'] == 3) &(val_df['vis'] == 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285a1f23-7199-4ce0-a26b-614ec52664d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df[(val_df['kid'] == 23) &(val_df['vis'] == 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5efdb0-d6fa-45f9-a635-82d051298e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df[(val_df['kid'] == 30) &(val_df['vis'] == 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf5c43a-9ce3-4790-8620-d2a2d2262b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the model is working very well even for rare classes, but we do not have too much cases to test... Augmentation is needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b09f9e9-b064-4194-9438-073561ee332d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
