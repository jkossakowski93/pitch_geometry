{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53221b0b-bbb5-4d9e-ae6b-17fbdddf5d6e",
   "metadata": {},
   "source": [
    "## 4 - preparation with augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90a3b81-aa1c-4f46-ab2f-19ef583a5dda",
   "metadata": {},
   "source": [
    "## classes with quite low mAP (classes to augment): 3, 23, 10, 30, 39, 19, 20, 21"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe09a52c-22a7-4a1c-aacf-07352566b80d",
   "metadata": {},
   "source": [
    "### 3, 23 - not enough data - need to augment\n",
    "### 19, 39 - confusion with 21 and 20 - perhaps bigger bounding box is needed - to be confirmed\n",
    "### 10 - low amount of data, but mAP is good. 30 if labelled correctly should be close to it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7077bfb0-4976-4524-8983-1ab451755fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a9a1ed-55d1-414f-9582-e68862d1e3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shutil\n",
    "from PIL import Image, ImageDraw, ImageEnhance\n",
    "import numpy as np\n",
    "import random\n",
    "# class, x_center, y_center, width, height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829db1c9-b1d6-486a-aec3-b562bfae13a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8884075d-c680-4cdc-86a1-d5ebe4da0e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(path+'\\\\train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c464cdb0-ee13-446e-aed1-983c83911e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(path+'\\\\val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2d3d05-272f-480d-9e0e-cb8af85cd857",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df = pd.read_csv('df_keypoints_corrected.csv').drop('Unnamed: 0', axis = 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb34e58a-7f33-432a-afc4-5c56d127373f",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd74262-32e5-47e3-846b-c6edc83e10d9",
   "metadata": {},
   "source": [
    "# Clipping and brightening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eecfbc3-a90b-420c-a2df-33bb1f48c525",
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames_with_3 = []\n",
    "for filename in labels_df['image_path'].unique():\n",
    "    temp_df = labels_df[labels_df['image_path'] == filename]\n",
    "    if (temp_df.loc[temp_df['kid'] == 3, 'vis'].values[0] == 2):\n",
    "        filenames_with_3.append(filename)\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8579a5-5df4-48a6-98ad-25bb7ac21b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(filenames_with_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f8971b-cfd9-4f32-a67f-64fd39b2e32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_val_df = pd.read_csv('vis_val_df_0.csv').drop('Unnamed: 0', axis = 1 )\n",
    "vis_train_df = pd.read_csv('vis_train_df_0.csv').drop('Unnamed: 0', axis = 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef7b048-e77b-4cea-92fe-2f24c7f99070",
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames_with_3_train = [item  for item in filenames_with_3 if item in vis_train_df['image_path'].unique()]\n",
    "filenames_with_3_val = [item  for item in filenames_with_3 if item in vis_val_df['image_path'].unique()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067f853d-d9c0-4e75-8b42-73568595f66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(filenames_with_3_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69dddcd7-6ba2-42dd-9fcd-12495fbb6583",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(filenames_with_3_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c79f985-5d49-4a48-8ae4-78a756e6552f",
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames_with_23 = []\n",
    "for filename in labels_df['image_path'].unique():\n",
    "    temp_df = labels_df[labels_df['image_path'] == filename]\n",
    "    if (temp_df.loc[temp_df['kid'] == 23, 'vis'].values[0] == 2):\n",
    "        filenames_with_23.append(filename)\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb6403e-2915-4c0a-b465-b5297df422e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(filenames_with_23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f791c4d5-6678-46ea-b1cf-e5a3745f76d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames_with_23_train = [item  for item in filenames_with_23 if item in vis_train_df['image_path'].unique()]\n",
    "filenames_with_23_val = [item  for item in filenames_with_23 if item in vis_val_df['image_path'].unique()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88225e36-2a33-43c8-b873-14cf9e68118c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(filenames_with_23_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302ba4fe-279a-41e6-a654-a83bba970253",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(filenames_with_23_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92270807-502f-4da2-b5ce-b10b0d2a3654",
   "metadata": {},
   "outputs": [],
   "source": [
    "path3 = 'C:\\\\Users\\\\Kossa\\\\Desktop\\\\respo_vision\\\\yolov7-pitch\\\\respo_dataset\\\\data_pitch_geom\\\\recruitment_task_pitch_geom'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413bd81a-5b79-4e77-8c62-51885d353ec4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for img_name in filenames_with_3:\n",
    "\n",
    "    img_name = img_name.split('/')[-1]\n",
    "\n",
    "    print(img_name)\n",
    "\n",
    "    img = mpimg.imread(path3+f'\\\\images\\\\train\\\\{img_name}')\n",
    "    imgplot = plt.imshow(img)\n",
    "\n",
    "    temp_df = labels_df[labels_df['image_path'] == f'images/train/{img_name}']\n",
    "    \n",
    "    # Annotation\n",
    "    for row in temp_df.itertuples():\n",
    "        if row.vis:\n",
    "            if row.x > 1000:\n",
    "                sign_x = -1\n",
    "            else:\n",
    "                sign_x = 1\n",
    "            if row.y < 500:\n",
    "                sign_y = 1\n",
    "            else:\n",
    "                sign_y = -1\n",
    "                \n",
    "            plt.annotate(row.kid, xy =(row.x , row.y ),\n",
    "                            xytext =(row.x + sign_x * 100, row.y + sign_y * 100), \n",
    "                            color = 'red', \n",
    "                            arrowprops = dict(facecolor ='red',\n",
    "                                              headwidth = 5,\n",
    "                                              headlength = 5,\n",
    "                                              width = 1,\n",
    "                                              shrink = 0.00001),)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ee720d-fcdb-4413-860c-6b65ff86a344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I do not want to overpopulate working classes, so I will select xClip (L and R) for each image, so it will only include points 3, 10 and 23, 30\n",
    "# I will clip y as well\n",
    "# skip 74f434bf605e8f6f5db0d409142bb7.jpg\n",
    "xclip_3_10_R = [\n",
    "    850,\n",
    "    750,\n",
    "    800,\n",
    "    800,\n",
    "    800,\n",
    "    900,\n",
    "    1100,\n",
    "    800,\n",
    "    750,\n",
    "    850,\n",
    "    900,\n",
    "    900,\n",
    "    900,\n",
    "    850,\n",
    "    850,\n",
    "    900,\n",
    "    900,\n",
    "    1250,\n",
    "    1100,\n",
    "    750,\n",
    "    750,\n",
    "    800,\n",
    "]\n",
    "\n",
    "xclip_3_10_L = [\n",
    "    50,\n",
    "    0,\n",
    "    10,\n",
    "    50,\n",
    "    20,\n",
    "    30,\n",
    "    100,\n",
    "    80,\n",
    "    0,\n",
    "    10,\n",
    "    0,\n",
    "    150,\n",
    "    140,\n",
    "    30,\n",
    "    60,\n",
    "    10,\n",
    "    40,\n",
    "    70,\n",
    "    50,\n",
    "    20,\n",
    "    30,\n",
    "    120,\n",
    "]\n",
    "\n",
    "# yclip_3_10 random od 200 do 400 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08768108-f280-4ce3-a585-6b8842450a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "xlip_for_filename_3_R = {filename:xclip for filename, xclip in zip(filenames_with_3, xclip_3_10_R)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6e9e5c-1b16-488b-8771-a883246acb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "xlip_for_filename_3_L = {filename:xclip for filename, xclip in zip(filenames_with_3, xclip_3_10_L)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef547871-065e-4e1b-88b8-dc964b0da83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "xlip_for_filename_3_R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20597e85-b714-4eb8-979f-a92452180333",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(xclip_3_10_L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc48c177-8da4-4d66-bf97-d451787c1472",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for img_name in filenames_with_23:\n",
    "\n",
    "    img_name = img_name.split('/')[-1]\n",
    "\n",
    "    print(img_name)\n",
    "\n",
    "    img = mpimg.imread(path3+f'\\\\images\\\\train\\\\{img_name}')\n",
    "    imgplot = plt.imshow(img)\n",
    "\n",
    "    temp_df = labels_df[labels_df['image_path'] == f'images/train/{img_name}']\n",
    "    \n",
    "    # Annotation\n",
    "    for row in temp_df.itertuples():\n",
    "        if row.vis:\n",
    "            if row.x > 1000:\n",
    "                sign_x = -1\n",
    "            else:\n",
    "                sign_x = 1\n",
    "            if row.y < 500:\n",
    "                sign_y = 1\n",
    "            else:\n",
    "                sign_y = -1\n",
    "                \n",
    "            plt.annotate(row.kid, xy =(row.x , row.y ),\n",
    "                            xytext =(row.x + sign_x * 100, row.y + sign_y * 100), \n",
    "                            color = 'red', \n",
    "                            arrowprops = dict(facecolor ='red',\n",
    "                                              headwidth = 5,\n",
    "                                              headlength = 5,\n",
    "                                              width = 1,\n",
    "                                              shrink = 0.00001),)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b37b46a-10ad-4b11-9965-4155b1fa7e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "xclip_23_30 = [\n",
    "    1100,\n",
    "    750,\n",
    "    1000,\n",
    "    1100,\n",
    "    900,\n",
    "    1100,\n",
    "    1200,\n",
    "    1000,\n",
    "    1100,\n",
    "    900,\n",
    "    900,\n",
    "    1000,\n",
    "    900,\n",
    "    1150,\n",
    "    750,\n",
    "    1100,\n",
    "    1150,\n",
    "    1000,\n",
    "    1000,\n",
    "    1000,\n",
    "    1000,\n",
    "    1000,\n",
    "    900,\n",
    "    900,\n",
    "    900,\n",
    "    1300,\n",
    "    1100,\n",
    "    900,\n",
    "    1100,\n",
    "    1150,\n",
    "    900,\n",
    "    1100,\n",
    "    1150,\n",
    "    1150,\n",
    "]\n",
    "    \n",
    "# y random 200 - 400 \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4c207c-d4c6-4afd-8118-695dfed27044",
   "metadata": {},
   "outputs": [],
   "source": [
    "xlip_for_filename_23 = {filename:xclip for filename, xclip in zip(filenames_with_23, xclip_23_30)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d81bb34-c753-49e8-8ae2-eef3dd03b8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "xlip_for_filename_23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9bbb007-19d2-46fe-b130-499ce3524775",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(xclip_23_30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01bffbd5-d86d-423a-a4d2-9ae80ea62e7b",
   "metadata": {},
   "source": [
    "## 2 ways to do this - clip and generate new - smaller image or gray everything else out (yolo will fit it to gray image anyway)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a158687-cfb8-4a07-949b-c1e9c85c9f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames_with_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126fddc2-4b65-464d-9f73-7cc8ffc7f536",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(path+'\\\\aug_3_10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6390dce6-6c52-44b9-99ce-0c0be44f66bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(path+'\\\\aug_3_10\\\\train')\n",
    "os.mkdir(path+'\\\\aug_3_10\\\\val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da31fe99-5666-4f94-b5d1-31f0b4304ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "xlip_for_filename_3_R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b72799-075b-4bcd-8c13-f204ca5f70c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames_with_3_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c1fad1-66ae-47a3-9ba5-965c0947ba89",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99387218-28f4-4166-bf6e-3c4d0b1dd0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(34)\n",
    "random_clip_dict = {}\n",
    "\n",
    "for img_name in filenames_with_3_train:\n",
    "\n",
    "    brightness_start = 0.4\n",
    "\n",
    "    for i in range(0,4):\n",
    "\n",
    "        xclip_R = xlip_for_filename_3_R[img_name]\n",
    "        xclip_L = xlip_for_filename_3_L[img_name]\n",
    "        xclip_R = xclip_R + random.randint(-50,50)\n",
    "        if xclip_L:\n",
    "            xclip_L = xclip_L + random.randint(-50,50)\n",
    "        yclip = random.randint(200,400)\n",
    "    \n",
    "        \n",
    "        img_name_s = img_name.split('/')[-1]\n",
    "    \n",
    "        print(img_name)\n",
    "    \n",
    "        # img = mpimg.imread(path3+f'\\\\images\\\\train\\\\{img_name}')\n",
    "        img = Image.open(path3+f'\\\\images\\\\train\\\\{img_name_s}')\n",
    "        # imgplot = plt.imshow(img)\n",
    "    \n",
    "        temp_df = labels_df[labels_df['image_path'] == f'images/train/{img_name_s}']\n",
    "        temp_df = temp_df[temp_df['x'] < xclip_R]\n",
    "    \n",
    "        # Size of the image in pixels (size of original image)\n",
    "        # (This is not mandatory)\n",
    "        width, height = img.size\n",
    "         \n",
    "        # Setting the points for cropped image\n",
    "        left = xclip_L\n",
    "        top = yclip\n",
    "        right = xclip_R\n",
    "        bottom = height\n",
    "    \n",
    "        \n",
    "         \n",
    "        # Cropped image of above dimension\n",
    "        # (It will not change original image)\n",
    "        im1 = img.crop((left, top, right, bottom))\n",
    "    \n",
    "        #image brightness enhancer\n",
    "        enhancer = ImageEnhance.Brightness(im1)\n",
    "        \n",
    "        im2 = enhancer.enhance(brightness_start)\n",
    "    \n",
    "        filename = img_name_s[:-4]\n",
    "    \n",
    "        im2.save(f'aug_3_10\\\\train\\\\{filename}_{i}.jpg')\n",
    "    \n",
    "        random_clip_dict[f'aug_3_10\\\\train\\\\{filename}_{i}.jpg'] = [xclip_R, xclip_L, yclip]\n",
    "\n",
    "        brightness_start += 0.4\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18ab877-1f74-49bc-8263-e92a614b5039",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(34)\n",
    "# random_clip_dict = {}\n",
    "\n",
    "for img_name in filenames_with_3_val:\n",
    "\n",
    "    brightness_start = 0.4\n",
    "\n",
    "    for i in range(0,4):\n",
    "\n",
    "        xclip_R = xlip_for_filename_3_R[img_name]\n",
    "        xclip_L = xlip_for_filename_3_L[img_name]\n",
    "        xclip_R = xclip_R + random.randint(-50,50)\n",
    "        if xclip_L:\n",
    "            xclip_L = xclip_L + random.randint(-50,50)\n",
    "        yclip = random.randint(200,400)\n",
    "    \n",
    "        \n",
    "        img_name_s = img_name.split('/')[-1]\n",
    "    \n",
    "        print(img_name)\n",
    "    \n",
    "        # img = mpimg.imread(path3+f'\\\\images\\\\train\\\\{img_name}')\n",
    "        img = Image.open(path3+f'\\\\images\\\\train\\\\{img_name_s}')\n",
    "        # imgplot = plt.imshow(img)\n",
    "    \n",
    "        temp_df = labels_df[labels_df['image_path'] == f'images/train/{img_name_s}']\n",
    "        temp_df = temp_df[temp_df['x'] < xclip_R]\n",
    "    \n",
    "        # Size of the image in pixels (size of original image)\n",
    "        # (This is not mandatory)\n",
    "        width, height = img.size\n",
    "         \n",
    "        # Setting the points for cropped image\n",
    "        left = xclip_L\n",
    "        top = yclip\n",
    "        right = xclip_R\n",
    "        bottom = height\n",
    "    \n",
    "        \n",
    "         \n",
    "        # Cropped image of above dimension\n",
    "        # (It will not change original image)\n",
    "        im1 = img.crop((left, top, right, bottom))\n",
    "    \n",
    "        #image brightness enhancer\n",
    "        enhancer = ImageEnhance.Brightness(im1)\n",
    "        \n",
    "        im2 = enhancer.enhance(brightness_start)\n",
    "    \n",
    "        filename = img_name_s[:-4]\n",
    "    \n",
    "        im2.save(f'aug_3_10\\\\val\\\\{filename}_{i}.jpg')\n",
    "    \n",
    "        random_clip_dict[f'aug_3_10\\\\val\\\\{filename}_{i}.jpg'] = [xclip_R, xclip_L, yclip]\n",
    "\n",
    "        brightness_start += 0.4\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55de171-cc4d-434e-a969-67ffed349ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(path+'\\\\aug_23_30')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9782ec8-b372-4ceb-9776-a702142434a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(path+'\\\\aug_23_30\\\\train')\n",
    "os.mkdir(path+'\\\\aug_23_30\\\\val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9289199d-f0d7-47e3-902f-7d44ad4f884b",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(34)\n",
    "# random_clip_dict = {}\n",
    "\n",
    "for img_name in filenames_with_23_train:\n",
    "\n",
    "    brightness_start = 0.4\n",
    "\n",
    "    for i in range(0,4):\n",
    "\n",
    "        xclip = xlip_for_filename_23[img_name]\n",
    "        xclip = xclip + random.randint(-50,50)\n",
    "        yclip = random.randint(200,400)\n",
    "    \n",
    "        \n",
    "        img_name_s = img_name.split('/')[-1]\n",
    "    \n",
    "        print(img_name)\n",
    "    \n",
    "        # img = mpimg.imread(path3+f'\\\\images\\\\train\\\\{img_name}')\n",
    "        img = Image.open(path3+f'\\\\images\\\\train\\\\{img_name_s}')\n",
    "        # imgplot = plt.imshow(img)\n",
    "    \n",
    "        temp_df = labels_df[labels_df['image_path'] == f'images/train/{img_name_s}']\n",
    "        temp_df = temp_df[temp_df['x'] < xclip_R]\n",
    "    \n",
    "        # Size of the image in pixels (size of original image)\n",
    "        # (This is not mandatory)\n",
    "        width, height = img.size\n",
    "         \n",
    "        # Setting the points for cropped image\n",
    "        left = xclip\n",
    "        top = yclip\n",
    "        right = 1920\n",
    "        bottom = height\n",
    "    \n",
    "        \n",
    "         \n",
    "        # Cropped image of above dimension\n",
    "        # (It will not change original image)\n",
    "        im1 = img.crop((left, top, right, bottom))\n",
    "    \n",
    "        #image brightness enhancer\n",
    "        enhancer = ImageEnhance.Brightness(im1)\n",
    "        \n",
    "        im2 = enhancer.enhance(brightness_start)\n",
    "    \n",
    "        filename = img_name_s[:-4]\n",
    "    \n",
    "        im2.save(f'aug_23_30\\\\train\\\\{filename}_{i}.jpg')\n",
    "    \n",
    "        random_clip_dict[f'aug_23_30\\\\train\\\\{filename}_{i}.jpg'] = [xclip,  yclip]\n",
    "\n",
    "        brightness_start += 0.4\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a28c136-c3c6-40a0-bed8-d5f7db053e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(34)\n",
    "# random_clip_dict = {}\n",
    "\n",
    "for img_name in filenames_with_23_val:\n",
    "\n",
    "    brightness_start = 0.4\n",
    "\n",
    "    for i in range(0,4):\n",
    "\n",
    "        xclip = xlip_for_filename_23[img_name]\n",
    "        xclip = xclip + random.randint(-50,50)\n",
    "        yclip = random.randint(200,400)\n",
    "    \n",
    "        \n",
    "        img_name_s = img_name.split('/')[-1]\n",
    "    \n",
    "        print(img_name)\n",
    "    \n",
    "        # img = mpimg.imread(path3+f'\\\\images\\\\train\\\\{img_name}')\n",
    "        img = Image.open(path3+f'\\\\images\\\\train\\\\{img_name_s}')\n",
    "        # imgplot = plt.imshow(img)\n",
    "    \n",
    "        temp_df = labels_df[labels_df['image_path'] == f'images/train/{img_name_s}']\n",
    "        temp_df = temp_df[temp_df['x'] < xclip_R]\n",
    "    \n",
    "        # Size of the image in pixels (size of original image)\n",
    "        # (This is not mandatory)\n",
    "        width, height = img.size\n",
    "         \n",
    "        # Setting the points for cropped image\n",
    "        left = xclip\n",
    "        top = yclip\n",
    "        right = 1920\n",
    "        bottom = height\n",
    "    \n",
    "        \n",
    "         \n",
    "        # Cropped image of above dimension\n",
    "        # (It will not change original image)\n",
    "        im1 = img.crop((left, top, right, bottom))\n",
    "    \n",
    "        #image brightness enhancer\n",
    "        enhancer = ImageEnhance.Brightness(im1)\n",
    "        \n",
    "        im2 = enhancer.enhance(brightness_start)\n",
    "    \n",
    "        filename = img_name_s[:-4]\n",
    "    \n",
    "        im2.save(f'aug_23_30\\\\val\\\\{filename}_{i}.jpg')\n",
    "    \n",
    "        random_clip_dict[f'aug_23_30\\\\val\\\\{filename}_{i}.jpg'] = [xclip,  yclip]\n",
    "\n",
    "        brightness_start += 0.4\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b4325d-508b-4d8d-8957-865983a23637",
   "metadata": {},
   "source": [
    "## generating labels: fall lables should be recalculated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef25e97-534b-4360-9139-cb6ba90731f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(path+'\\\\aug_3_10\\\\train\\\\labels')\n",
    "os.mkdir(path+'\\\\aug_3_10\\\\val\\\\labels')\n",
    "os.mkdir(path+'\\\\aug_23_30\\\\train\\\\labels')\n",
    "os.mkdir(path+'\\\\aug_23_30\\\\val\\\\labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb324d0-1b94-4285-b99e-e76c5b3c225f",
   "metadata": {},
   "outputs": [],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949b2f4e-6970-45b5-86e3-50d911b54039",
   "metadata": {},
   "outputs": [],
   "source": [
    "# <object-class-id> <x> <y> <width> <height>\n",
    "label_pad = 50 #px\n",
    "# label_pad_30 = 80 # in fact I will increase bounding box for class 30\n",
    "for img_name in filenames_with_3_train:\n",
    "# for df in vis_train_df.groupby('image_path'):\n",
    "    # print(df[1]['x'])\n",
    "    # xclip = xlip_for_filename_3[img_name]\n",
    "\n",
    "    filename = img_name.split('/')[-1][:-4]\n",
    "\n",
    "    # print(filename, '\\n')\n",
    "    for i in range(4):\n",
    "        xclip_R, xclip_L, yclip = random_clip_dict[f'aug_3_10\\\\train\\\\{filename}_{i}.jpg']\n",
    "        temp_df = vis_train_df[(vis_train_df['image_path'] == img_name) & (vis_train_df['x'] < xclip_R)]\n",
    "        \n",
    "        with open(f'{path}\\\\aug_3_10\\\\train\\\\labels\\\\{filename}_{i}.txt', 'w') as file:\n",
    "            for row in temp_df.itertuples():\n",
    "                # x_l = row.x - label_pad\n",
    "                # x_p = row.x + label_pad\n",
    "                # if x_l < 0: x_l = 0\n",
    "                # if x_p > 1920: x_l = 1920\n",
    "                # y_t = row.y - label_pad\n",
    "                # y_b = row.y + label_pad\n",
    "                # if y_t < 0: y_t = 0\n",
    "                # if y_b > 1080: y_b = 1080\n",
    "                if not row.vis:\n",
    "                    continue\n",
    "                else:\n",
    "                    file.write(f'{row.kid} {(row.x - xclip_L)/(xclip_R - xclip_L)} {(row.y - yclip)/(1080 - yclip)} {2*label_pad/(xclip_R - xclip_L)} {2*label_pad/(1080 - yclip)}\\n')\n",
    "                # print((f'{row.kid} {row.x/1920} {row.y/1080} {2*label_pad/1920} {2*label_pad/1080}'))\n",
    "            \n",
    "        # print(rx_l = row.x - 50)\n",
    "        # print(row.y)\n",
    "    # print(object_class_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f0ef6e-e2e7-40bb-b883-914cd40592c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "random_clip_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4ae90a-a669-4150-bf1b-633e4f1eabe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# <object-class-id> <x> <y> <width> <height>\n",
    "label_pad = 50 #px\n",
    "# label_pad_30 = 80 # in fact I will increase bounding box for class 30\n",
    "for img_name in filenames_with_3_val:\n",
    "# for df in vis_train_df.groupby('image_path'):\n",
    "    # print(df[1]['x'])\n",
    "    \n",
    "    filename = img_name.split('/')[-1][:-4]\n",
    "\n",
    "    # print(filename, '\\n')\n",
    "    for i in range(4):\n",
    "        xclip_R, xclip_L, yclip = random_clip_dict[f'aug_3_10\\\\val\\\\{filename}_{i}.jpg']\n",
    "        temp_df = vis_val_df[(vis_val_df['image_path'] == img_name) & (vis_val_df['x'] < xclip_R)]\n",
    "        \n",
    "        with open(f'{path}\\\\aug_3_10\\\\val\\\\labels\\\\{filename}_{i}.txt', 'w') as file:\n",
    "            for row in temp_df.itertuples():\n",
    "                # x_l = row.x - label_pad\n",
    "                # x_p = row.x + label_pad\n",
    "                # if x_l < 0: x_l = 0\n",
    "                # if x_p > 1920: x_l = 1920\n",
    "                # y_t = row.y - label_pad\n",
    "                # y_b = row.y + label_pad\n",
    "                # if y_t < 0: y_t = 0\n",
    "                # if y_b > 1080: y_b = 1080\n",
    "                if not row.vis:\n",
    "                    continue\n",
    "                else:\n",
    "                    file.write(f'{row.kid} {(row.x - xclip_L)/(xclip_R - xclip_L)} {(row.y - yclip)/(1080 - yclip)} {2*label_pad/(xclip_R - xclip_L)} {2*label_pad/(1080 - yclip)}\\n')\n",
    "                # print((f'{row.kid} {row.x/1920} {row.y/1080} {2*label_pad/1920} {2*label_pad/1080}'))\n",
    "            \n",
    "        # print(rx_l = row.x - 50)\n",
    "        # print(row.y)\n",
    "    # print(object_class_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c872ab-d0c9-4e5e-84a0-2af64067b2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random.seed(0)\n",
    "\n",
    "class_name_to_id_mapping = {str(i):i for i in range(40)}\n",
    "\n",
    "class_id_to_name_mapping = dict(zip(class_name_to_id_mapping.values(), class_name_to_id_mapping.keys()))\n",
    "\n",
    "def plot_bounding_box(image, annotation_list):\n",
    "    annotations = np.array(annotation_list)\n",
    "    w, h = image.size\n",
    "    \n",
    "    plotted_image = ImageDraw.Draw(image)\n",
    "\n",
    "    transformed_annotations = np.copy(annotations)\n",
    "    transformed_annotations[:,[1,3]] = annotations[:,[1,3]] * w\n",
    "    transformed_annotations[:,[2,4]] = annotations[:,[2,4]] * h \n",
    "    \n",
    "    transformed_annotations[:,1] = transformed_annotations[:,1] - (transformed_annotations[:,3] / 2)\n",
    "    transformed_annotations[:,2] = transformed_annotations[:,2] - (transformed_annotations[:,4] / 2)\n",
    "    transformed_annotations[:,3] = transformed_annotations[:,1] + transformed_annotations[:,3]\n",
    "    transformed_annotations[:,4] = transformed_annotations[:,2] + transformed_annotations[:,4]\n",
    "    \n",
    "    for ann in transformed_annotations:\n",
    "        obj_cls, x0, y0, x1, y1 = ann\n",
    "        plotted_image.rectangle(((x0,y0), (x1,y1)))\n",
    "        \n",
    "        plotted_image.text((x0, y0 - 10), class_id_to_name_mapping[(int(obj_cls))])\n",
    "    \n",
    "    plt.imshow(np.array(image))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94bee62-7779-4c08-b333-b23b7cd5febd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for filename in filenames_with_3_train:\n",
    "    \n",
    "    \n",
    "    filename = filename.split('/')[-1][:-4]\n",
    "\n",
    "    for i in range(4):\n",
    "\n",
    "        img_path = f'{path}\\\\aug_3_10\\\\train\\\\{filename}_{i}.jpg'\n",
    "        labels_path = f'{path}\\\\aug_3_10\\\\train\\\\labels\\\\{filename}_{i}.txt'\n",
    "    \n",
    "            \n",
    "        \n",
    "        image = Image.open(img_path)\n",
    "        with open(labels_path, 'r') as file:\n",
    "            labels = file.readlines()\n",
    "    \n",
    "        \n",
    "        annotation_file = labels_path\n",
    "        with open(annotation_file, \"r\") as file:\n",
    "            annotation_list = file.read().split(\"\\n\")[:-1]\n",
    "            annotation_list = [x.split(\" \") for x in annotation_list]\n",
    "            annotation_list = [[float(y) for y in x ] for x in annotation_list]\n",
    "    \n",
    "        plot_bounding_box(image, annotation_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9df1d70-008d-4bec-a2a3-bde6a3a3a980",
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in filenames_with_3_val:\n",
    "    \n",
    "    filename = filename.split('/')[-1][:-4]\n",
    "\n",
    "    for i in range(4):\n",
    "    \n",
    "        img_path = f'{path}\\\\aug_3_10\\\\val\\\\{filename}_{i}.jpg'\n",
    "        labels_path = f'{path}\\\\aug_3_10\\\\val\\\\labels\\\\{filename}_{i}.txt'\n",
    "        \n",
    "        image = Image.open(img_path)\n",
    "        with open(labels_path, 'r') as file:\n",
    "            labels = file.readlines()\n",
    "        \n",
    "        annotation_file = labels_path\n",
    "        with open(annotation_file, \"r\") as file:\n",
    "            annotation_list = file.read().split(\"\\n\")[:-1]\n",
    "            annotation_list = [x.split(\" \") for x in annotation_list]\n",
    "            annotation_list = [[float(y) for y in x ] for x in annotation_list]\n",
    "            \n",
    "        # arr_labels = np.array([b_list]).reshape(len(b_list), 5)\n",
    "        #Plot the Bounding Box\n",
    "        plot_bounding_box(image, annotation_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3867fa2b-c65d-4a44-b8ce-572037a8ebb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# <object-class-id> <x> <y> <width> <height>\n",
    "label_pad = 50 #px\n",
    "# label_pad_30 = 80 # in fact I will increase bounding box for class 30\n",
    "for img_name in filenames_with_23_train:\n",
    "\n",
    "    filename = img_name.split('/')[-1][:-4]\n",
    "\n",
    "    # print(filename, '\\n')\n",
    "    for i in range(4):\n",
    "        xclip_L, yclip = random_clip_dict[f'aug_23_30\\\\train\\\\{filename}_{i}.jpg']\n",
    "        temp_df = vis_train_df[(vis_train_df['image_path'] == img_name) & (vis_train_df['x'] > xclip_L)]\n",
    "        \n",
    "        with open(f'{path}\\\\aug_23_30\\\\train\\\\labels\\\\{filename}_{i}.txt', 'w') as file:\n",
    "            for row in temp_df.itertuples():\n",
    "\n",
    "                if not row.vis:\n",
    "                    continue\n",
    "                else:\n",
    "                    file.write(f'{row.kid} {(row.x - xclip_L)/(1920 - xclip_L)} {(row.y - yclip)/(1080 - yclip)} {2*label_pad/(1920 - xclip_L)} {2*label_pad/(1080 - yclip)}\\n')\n",
    "                # print((f'{row.kid} {row.x/1920} {row.y/1080} {2*label_pad/1920} {2*label_pad/1080}'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b98bdb-773e-4ebb-9f1f-fc8a74fa17bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# <object-class-id> <x> <y> <width> <height>\n",
    "label_pad = 50 #px\n",
    "# label_pad_30 = 80 # in fact I will increase bounding box for class 30\n",
    "for img_name in filenames_with_23_val:\n",
    "\n",
    "    filename = img_name.split('/')[-1][:-4]\n",
    "\n",
    "    for i in range(4):\n",
    "        xclip_L, yclip = random_clip_dict[f'aug_23_30\\\\val\\\\{filename}_{i}.jpg']\n",
    "        temp_df = vis_val_df[(vis_val_df['image_path'] == img_name) & (vis_val_df['x'] > xclip_L)]\n",
    "        \n",
    "        with open(f'{path}\\\\aug_23_30\\\\val\\\\labels\\\\{filename}_{i}.txt', 'w') as file:\n",
    "            for row in temp_df.itertuples():\n",
    "\n",
    "                if not row.vis:\n",
    "                    continue\n",
    "                else:\n",
    "                    file.write(f'{row.kid} {(row.x - xclip_L)/(1920 - xclip_L)} {(row.y - yclip)/(1080 - yclip)} {2*label_pad/(1920 - xclip_L)} {2*label_pad/(1080 - yclip)}\\n')\n",
    "                # print((f'{row.kid} {row.x/1920} {row.y/1080} {2*label_pad/1920} {2*label_pad/1080}'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a24537-f0cb-41d6-be05-45e72afcc936",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for filename in filenames_with_23_train:\n",
    "    \n",
    "    filename = filename.split('/')[-1][:-4]\n",
    "\n",
    "    for i in range(4):\n",
    "\n",
    "        img_path = f'{path}\\\\aug_23_30\\\\train\\\\{filename}_{i}.jpg'\n",
    "        labels_path = f'{path}\\\\aug_23_30\\\\train\\\\labels\\\\{filename}_{i}.txt'\n",
    "    \n",
    "        image = Image.open(img_path)\n",
    "        with open(labels_path, 'r') as file:\n",
    "            labels = file.readlines()\n",
    "    \n",
    "        \n",
    "        annotation_file = labels_path\n",
    "        with open(annotation_file, \"r\") as file:\n",
    "            annotation_list = file.read().split(\"\\n\")[:-1]\n",
    "            annotation_list = [x.split(\" \") for x in annotation_list]\n",
    "            annotation_list = [[float(y) for y in x ] for x in annotation_list]\n",
    "            \n",
    "        # arr_labels = np.array([b_list]).reshape(len(b_list), 5)\n",
    "        #Plot the Bounding Box\n",
    "        plot_bounding_box(image, annotation_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b37dfab-d3d3-42b6-9cf2-7bd8088ba40e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for filename in filenames_with_23_val:\n",
    "    \n",
    "    filename = filename.split('/')[-1][:-4]\n",
    "\n",
    "    for i in range(4):\n",
    "\n",
    "        img_path = f'{path}\\\\aug_23_30\\\\val\\\\{filename}_{i}.jpg'\n",
    "        labels_path = f'{path}\\\\aug_23_30\\\\val\\\\labels\\\\{filename}_{i}.txt'\n",
    "    \n",
    "        image = Image.open(img_path)\n",
    "        with open(labels_path, 'r') as file:\n",
    "            labels = file.readlines()\n",
    "    \n",
    "        \n",
    "        annotation_file = labels_path\n",
    "        with open(annotation_file, \"r\") as file:\n",
    "            annotation_list = file.read().split(\"\\n\")[:-1]\n",
    "            annotation_list = [x.split(\" \") for x in annotation_list]\n",
    "            annotation_list = [[float(y) for y in x ] for x in annotation_list]\n",
    "            \n",
    "        # arr_labels = np.array([b_list]).reshape(len(b_list), 5)\n",
    "        #Plot the Bounding Box\n",
    "        plot_bounding_box(image, annotation_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b649a4-689b-46e9-b8f8-ac9c128a545b",
   "metadata": {},
   "source": [
    "## first stage - brightening and multiplaying images for critical classes is ready - images will be added to training and validating datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa8b6b5-bbfd-4382-a366-c35885ae7f62",
   "metadata": {},
   "source": [
    "## Second idea - perhaps bigger bounding boxes are needed for problematic classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8254b0-ed05-498a-b777-1e958f65342a",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df = labels_df[labels_df['dataset'] == 'train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3805b43-c2f4-4ae5-a4ba-819853b75e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16705d4-c529-4cb0-b833-e6c070045617",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images = labels_df['image_path'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54b044a-60c7-4ee7-8702-bf7c22fe12a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_images = [item.split('/')[-1] for item in all_images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac260b1a-97fa-45fd-a9a4-ed252f5f1877",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train, val = train_test_split(all_images, test_size=0.2, random_state=43, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8f425c-b9de-4bae-ad60-59c82437bfa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd85f653-225a-4d50-b18c-4e958473d3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ab8b8d-52eb-4ce6-af2e-54bc1d669c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = labels_df[labels_df['image_path'].isin(train)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd2b369-54a7-4a49-8a6a-cdbce623ae33",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df = labels_df[labels_df['image_path'].isin(val)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85033dd-94db-4d0d-a946-a55adb9f6928",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632689f1-5c20-49c3-b227-6ff0a9b9767a",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df.to_csv('val_df_0.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb8090c-057d-475e-8a45-8d6bd4bc1b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_train_df = train_df[train_df['vis']==2]\n",
    "vis_val_df = val_df[val_df['vis']==2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32401706-0624-4928-8f7d-d4ff2635c970",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_val_df.to_csv('vis_val_df_0.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6439b13e-3d5b-435f-9c88-a3cc065e015f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(vis_val_df) / len(vis_train_df) # in fact it is 0.244 split but its ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f749e0fa-07b8-4d6d-95a6-5ccce9b89e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (16, 4))\n",
    "plt.bar(vis_train_df.groupby('kid').count()['x'].index, vis_train_df.groupby('kid').count()['x'])\n",
    "plt.xticks(rotation = 45)\n",
    "plt.xticks(vis_train_df.groupby('kid').count()['x'].index)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a796f773-7211-4f75-a814-a899ec52dd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (16, 4))\n",
    "plt.bar(vis_val_df.groupby('kid').count()['x'].index, vis_val_df.groupby('kid').count()['x'])\n",
    "plt.xticks(rotation = 45)\n",
    "plt.xticks(vis_val_df.groupby('kid').count()['x'].index)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20e057a-78ba-4da8-b0dc-10f3811f2af7",
   "metadata": {},
   "source": [
    "## class balance comparison between train and test is fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a453db9-d4a2-482b-8e5d-5c663f904484",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check for leakage\n",
    "for item in train:\n",
    "    if item in val:\n",
    "        print(\"!\")\n",
    "for item in val:\n",
    "    if item in train:\n",
    "        print(\"!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35fedab-b730-4fae-9d7a-7985849472d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(path+'\\\\train\\\\images')\n",
    "os.mkdir(path+'\\\\train\\\\labels')\n",
    "os.mkdir(path+'\\\\val\\\\images')\n",
    "os.mkdir(path+'\\\\val\\\\labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f205eb56-4c9b-4be3-b27a-5446d27e7b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "path2 = 'C:\\\\Users\\\\Kossa\\\\Desktop\\\\respo_vision\\\\yolov7-pitch\\\\respo_dataset\\\\data_pitch_geom\\\\recruitment_task_pitch_geom'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49a0bd5-1bd8-4fcd-853b-38199546ed62",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for img_path in train:\n",
    "#     filename = img_path.split('/')[-1]\n",
    "#     shutil.copy(path2+f'\\\\images\\\\train\\\\{filename}', path+f'\\\\train\\\\images\\\\{filename}')\n",
    "\n",
    "\n",
    "# Some files are mislabeled as training data, but they do not have any labels, despite the points are visible. \n",
    "# I will ignore them and check for vis == 2\n",
    "\n",
    "for img_path in vis_train_df['image_path'].unique():\n",
    "    filename = img_path.split('/')[-1]\n",
    "    shutil.copy(path2+f'\\\\images\\\\train\\\\{filename}', path+f'\\\\train\\\\images\\\\{filename}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e727f2-f22d-429c-8a81-b1404411cd4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for img_path in val:\n",
    "#     filename = img_path.split('/')[-1]\n",
    "#     shutil.copy(path2+f'\\\\images\\\\train\\\\{filename}', path+f'\\\\val\\\\images\\\\{filename}')\n",
    "\n",
    "for img_path in vis_val_df['image_path'].unique():\n",
    "    filename = img_path.split('/')[-1]\n",
    "    shutil.copy(path2+f'\\\\images\\\\train\\\\{filename}', path+f'\\\\val\\\\images\\\\{filename}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe074de-d816-4583-9f54-3f9e208da6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "no_vis_classes_train = []\n",
    "for img_path in train:\n",
    "    filename = img_path.split('/')[-1]\n",
    "    # shutil.copy(path2+f'\\\\images\\\\train\\\\{filename}', path+f'\\\\val\\\\images\\\\{filename}')\n",
    "    if filename not in [item.split('/')[-1] for item in vis_train_df['image_path'].unique()]:\n",
    "        no_vis_classes_train.append(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b116609-2974-4e9e-8cd2-3d9e15d72e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_vis_classes_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16de3cf-4759-46be-9f22-21156f2605f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "no_vis_classes_val = []\n",
    "for img_path in val:\n",
    "    filename = img_path.split('/')[-1]\n",
    "    # shutil.copy(path2+f'\\\\images\\\\train\\\\{filename}', path+f'\\\\val\\\\images\\\\{filename}')\n",
    "    if filename not in [item.split('/')[-1] for item in vis_val_df['image_path'].unique()]:\n",
    "        no_vis_classes_val.append(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d02b52-51cb-407a-84f9-2b18c7cbc9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_vis_classes_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882385ec-5063-40e7-a4bc-f22c66300c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this includes above no vis classes - useful for testing but not for training\n",
    "for img_path in val:\n",
    "    filename = img_path.split('/')[-1]\n",
    "    shutil.copy(path2+f'\\\\images\\\\train\\\\{filename}', path+f'\\\\val\\\\images\\\\{filename}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44d9443-b184-4af0-b52c-f828f41357d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# <object-class-id> <x> <y> <width> <height>\n",
    "cls_with_bigger_box = [3, 23, 10, 30, 39, 19, 20, 21]\n",
    "label_pad = 50 #px\n",
    "bigger_label_pad = 80 # 60 % bigger, becasue its x2\n",
    "for df in vis_train_df.groupby('image_path'):\n",
    "    # print(df[1]['x'])\n",
    "    filename = df[0].split('/')[-1][:-4]\n",
    "    # print(filename, '\\n')\n",
    "    with open(f'{path}\\\\train\\\\labels\\\\{filename}.txt', 'w') as file:\n",
    "        for row in df[1].itertuples():\n",
    "\n",
    "            if not row.vis:\n",
    "                continue\n",
    "            else:\n",
    "                if row.kid in cls_with_bigger_box:\n",
    "                    file.write(f'{row.kid} {row.x/1920} {row.y/1080} {2*bigger_label_pad/1920} {2*bigger_label_pad/1080}\\n')\n",
    "                else:\n",
    "                    file.write(f'{row.kid} {row.x/1920} {row.y/1080} {2*label_pad/1920} {2*label_pad/1080}\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c78c8e-e63a-40a8-b2da-e00d18adfeab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# <object-class-id> <x> <y> <width> <height>\n",
    "label_pad = 50 #px\n",
    "bigger_label_pad = 80\n",
    "# for df in vis_val_df.groupby('image_path'):    # for training\n",
    "for df in val_df.groupby('image_path'):    # for testing\n",
    "    # print(df[1]['x'])\n",
    "    filename = df[0].split('/')[-1][:-4]\n",
    "    with open(f'{path}\\\\val\\\\labels\\\\{filename}.txt', 'w') as file:\n",
    "        for row in df[1].itertuples():\n",
    "\n",
    "            if not row.vis:\n",
    "                continue\n",
    "            else:\n",
    "                if row.kid in cls_with_bigger_box:\n",
    "                    file.write(f'{row.kid} {row.x/1920} {row.y/1080} {2*bigger_label_pad/1920} {2*bigger_label_pad/1080}\\n')\n",
    "                else:\n",
    "                    file.write(f'{row.kid} {row.x/1920} {row.y/1080} {2*label_pad/1920} {2*label_pad/1080}\\n')\n",
    "        \n",
    "        # print(rx_l = row.x - 50)\n",
    "        # print(row.y)\n",
    "    # print(object_class_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e3a3d5-f184-4f71-b54f-aa88cabf2267",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random.seed(0)\n",
    "\n",
    "class_name_to_id_mapping = {str(i):i for i in range(40)}\n",
    "\n",
    "class_id_to_name_mapping = dict(zip(class_name_to_id_mapping.values(), class_name_to_id_mapping.keys()))\n",
    "\n",
    "def plot_bounding_box(image, annotation_list):\n",
    "    annotations = np.array(annotation_list)\n",
    "    w, h = image.size\n",
    "    \n",
    "    plotted_image = ImageDraw.Draw(image)\n",
    "\n",
    "    transformed_annotations = np.copy(annotations)\n",
    "    transformed_annotations[:,[1,3]] = annotations[:,[1,3]] * w\n",
    "    transformed_annotations[:,[2,4]] = annotations[:,[2,4]] * h \n",
    "    \n",
    "    transformed_annotations[:,1] = transformed_annotations[:,1] - (transformed_annotations[:,3] / 2)\n",
    "    transformed_annotations[:,2] = transformed_annotations[:,2] - (transformed_annotations[:,4] / 2)\n",
    "    transformed_annotations[:,3] = transformed_annotations[:,1] + transformed_annotations[:,3]\n",
    "    transformed_annotations[:,4] = transformed_annotations[:,2] + transformed_annotations[:,4]\n",
    "    \n",
    "    for ann in transformed_annotations:\n",
    "        obj_cls, x0, y0, x1, y1 = ann\n",
    "        plotted_image.rectangle(((x0,y0), (x1,y1)))\n",
    "        \n",
    "        plotted_image.text((x0, y0 - 10), class_id_to_name_mapping[(int(obj_cls))])\n",
    "    \n",
    "    plt.imshow(np.array(image))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37b0282-5021-4dea-baec-64f7daa12c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '0a996c430c38f452eb39b86b0b9b07'\n",
    "img_path = f'{path}\\\\train\\\\images\\\\{filename}.jpg'\n",
    "labels_path = f'{path}\\\\train\\\\labels\\\\{filename}.txt'\n",
    "\n",
    "image = Image.open(img_path)\n",
    "with open(labels_path, 'r') as file:\n",
    "    labels = file.readlines()\n",
    "\n",
    "annotation_file = labels_path\n",
    "with open(annotation_file, \"r\") as file:\n",
    "    annotation_list = file.read().split(\"\\n\")[:-1]\n",
    "    annotation_list = [x.split(\" \") for x in annotation_list]\n",
    "    annotation_list = [[float(y) for y in x ] for x in annotation_list]\n",
    "    \n",
    "# arr_labels = np.array([b_list]).reshape(len(b_list), 5)\n",
    "#Plot the Bounding Box\n",
    "plot_bounding_box(image, annotation_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e442f87-9d74-4b53-9148-8bb09d52da2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '16bafd79da7d6a6c2e6893f1ffb4d9'\n",
    "img_path = f'{path}\\\\train\\\\images\\\\{filename}.jpg'\n",
    "labels_path = f'{path}\\\\train\\\\labels\\\\{filename}.txt'\n",
    "\n",
    "image = Image.open(img_path)\n",
    "with open(labels_path, 'r') as file:\n",
    "    labels = file.readlines()\n",
    "\n",
    "annotation_file = labels_path\n",
    "with open(annotation_file, \"r\") as file:\n",
    "    annotation_list = file.read().split(\"\\n\")[:-1]\n",
    "    annotation_list = [x.split(\" \") for x in annotation_list]\n",
    "    annotation_list = [[float(y) for y in x ] for x in annotation_list]\n",
    "    \n",
    "# arr_labels = np.array([b_list]).reshape(len(b_list), 5)\n",
    "#Plot the Bounding Box\n",
    "plot_bounding_box(image, annotation_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fab9337-1a95-4a33-865b-92db7fdeb6da",
   "metadata": {},
   "source": [
    "## last step is to check how bounding boxes fit estimated point 30 position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13e4a3a-f595-42ec-955e-b9c0272f8c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_30_list = [\n",
    "'9677b5248c7d2a391bb331263538c8.jpg',\n",
    "'4fca4e0d72eef70eb308f4e92931b3.jpg',\n",
    "'74f434bf605e8f6f5db0d409142bb7.jpg',\n",
    "'fa9255414e8e18aa257670935fffba.jpg',\n",
    "'60d86f695f30c394960023f391f50d.jpg',\n",
    "'b73ab787697aec7a29675a88e771da.jpg',\n",
    "'5fcf8d794a1c34024cc2c9efc285d9.jpg',\n",
    "'b5d9188836d57ad32c0820713ab33e.jpg',\n",
    "'41e9761846a0f10a8e6aecef400413.jpg',\n",
    "'8dea69d0d05031d04d2b85af2a0705.jpg',\n",
    "'2f1d6e937128e45c8257bf4b76db2e.jpg',\n",
    "'cbf9e8794cd6aa406d2fc18946b89c.jpg',\n",
    "'c05f429dbf4abeebeb4fa2e4937db8.jpg',\n",
    "'2abe6d162668bb85bd8844103d58b3.jpg',\n",
    "'ab65a0ffacb84533cf601a236f0920.jpg',\n",
    "'38829ff54c7b1db3f49a31a1d5ece5.jpg',\n",
    "'236e289ccb95432f1bbe07cf106c3b.jpg',\n",
    "'2ef80b5e833ab9a2a3e269489dbf8d.jpg',\n",
    "'a5941c096e19a477c13bb973e09df7.jpg',\n",
    "'63cb5a548cd1032174d6605fabd290.jpg',\n",
    "'4ef2046190bda2894769bf65e33ce7.jpg',\n",
    "'3a4218907b274807c74be14032c901.jpg',\n",
    "'78605986e67c9b89f1a807e858fe29.jpg',\n",
    "'0676caa13e8abe3a568a2c61ef6e2d.jpg',\n",
    "'f658ca5bdf4d8ee04fa3d648c9cc4f.jpg',\n",
    "'7b304f4cd963b2fe573c3840315e79.jpg',\n",
    "'66fa19216e23d7596b4d90da268e7c.jpg',# 33 confusion!!!!!!\n",
    "'a1401f391b8f64656723df05c36b24.jpg',\n",
    "'2791f191af7fca4b2e0b77cd050629.jpg',\n",
    "'86a2a40a485feed061b6c5b5f961ee.jpg',\n",
    "'c4f1f57482859c60ef0742691607f9.jpg',\n",
    "'9ed1c1c9ee6cb5d5dbd61727d1c412.jpg',\n",
    "'67d48e85a7792f3823b38c20a8ebf3.jpg',\n",
    "'29c16eecccde846baba0b4f8bb5027.jpg',\n",
    "'6546c56f291892f9b07a83eb2b1994.jpg',\n",
    "'fdbab61c397896251067d8becc67e6.jpg',\n",
    "'56c34b486748121bc22586949b0692.jpg',\n",
    "'cdf10c1766c99298fed520400472a0.jpg',\n",
    "'05a0d9cef3fb5fca8757e07b3bd867.jpg',\n",
    "'a7267b1486cf8f8f8705e32452199e.jpg',\n",
    "'ea158fb0fe07da57f02ff65684a647.jpg',\n",
    "'335155589d1642be50e4de8953a6bf.jpg',\n",
    "'2356ce9513bb1fe22364646639add7.jpg',\n",
    "'9f8359d4bc8d2e63a0ce666f1936fd.jpg',\n",
    "'9997dcea7cf66fe6e57fb36233208d.jpg',\n",
    "'472fded23adc33c9a8bd5f7cbfd6b8.jpg',\n",
    "'48d469d5006ce73f21e4be55a4f706.jpg',\n",
    "'d4e0605f208a8365540f188d419ca6.jpg',\n",
    "'e575b9605fb6f9fd6f729f393398b3.jpg',\n",
    "'e25802bee03661511ddf0813904fea.jpg',\n",
    "'a270c12019e0005c93e28ca45b06dd.jpg',\n",
    "'a6eddc8c6d6d2afdbc871bf39ad49d.jpg',\n",
    "'48f9c434173add06c222a44b3a95e4.jpg',\n",
    "'62de8876e9adc7aa23af2ab13ec754.jpg',\n",
    "'5f9a45153673ad24eb9f4ce6654ff1.jpg',\n",
    "'0d0365deb03c4703e978f360d5ff72.jpg',\n",
    "'710728f1a99225235e22abc62aeaab.jpg',\n",
    "'02015eb88e33614b36170db06784d5.jpg',\n",
    "'164bc44b724a585ae72e69ace0a10b.jpg',\n",
    "'385acceeae6be647e931135c06bbea.jpg',\n",
    "'2c4ff6598a91a53d7706ac185df094.jpg',\n",
    "'92ffc7f0174f2e1e88ea739aef1f3f.jpg',\n",
    "'a2cd5ab3d4985525865e565111eeeb.jpg',\n",
    "'9bda0e6d253f33d80d4611f795a0c9.jpg',\n",
    "'8f1bba299aa3484fc57a5a685e7be1.jpg',\n",
    "'54fbd9767485472fa92a665b5ad9ff.jpg',\n",
    "'2faca0c080867d91e5f7991b19f845.jpg',\n",
    "'172dca5da5144cdb86558b9a6f1308.jpg',\n",
    "'6e1f06d09ea276cc6c2e0d233facc3.jpg',\n",
    "'d1f64e3430882e41de16b6b879fd9b.jpg',\n",
    "'09f0bf76cd672ba841c926d8fdbfc8.jpg',\n",
    "'03cc1aaab2c0985634cf4fa638b63a.jpg',\n",
    "'cee6864c0ab20423896373ee8328d3.jpg',\n",
    "'245f3357b3f3c7e97278610664ab8b.jpg',  ### specific orientation\n",
    "'e681aa8ce2ce22486fd5d6d5870d2d.jpg',\n",
    "'aef893839b0d08bc307f6c5b581c95.jpg',\n",
    "'db6d9c9a386a306a65ed3939b65816.jpg',\n",
    "'33b745960e851d2fd95e4abd6be141.jpg',\n",
    "'0333a911c259ffb96e045cc998657f.jpg',\n",
    "'75082ed4b6d5cf01ca376bbf67bcd8.jpg',\n",
    "'00e6fafafd740664bef9aa4f387359.jpg',\n",
    "'2c90e1733e23e5e56dbd63db45c63d.jpg',\n",
    "'24e341f3e6399b9ad5864374a2a3c9.jpg',\n",
    "'879b988c4b4d8f07709e2fd60510cf.jpg',\n",
    "'05774d01da335be8ca3e263d622fdb.jpg',\n",
    "'b5c506b0396c461aacf3c97e64afcf.jpg',\n",
    "'a64c0ae39bb932c6a2eee247170c61.jpg',\n",
    "'57de493eb70d824253227ddddbad86.jpg',\n",
    "'17c0fd4742d6f872316ee1dd4959b8.jpg',\n",
    "'21a05750e2d5fda4e77ebb179b86ea.jpg',\n",
    "'1d2f4e3883651bb8a261cd1df3fcb6.jpg', ### specific orientation\n",
    "'94b49ca68ed419da8ddbccd73dfd03.jpg', ### specific orientation\n",
    "'fc8446a9d0ccde9c5d6cb10c6d3883.jpg',\n",
    "'679fe17d8e3159e151938b5d8b3d83.jpg',\n",
    "'b31a75c2688625e447879c620ac151.jpg',\n",
    "'98b8d1e43aa64028280da5c354d459.jpg',\n",
    "'65342549664333e6167919ff91fe47.jpg',\n",
    "'06852b013d652b6850cba20fff83d8.jpg',\n",
    "'bfc68987f3a82449d5533cb046deef.jpg',\n",
    "'6ac91cbebe6df9a2669b1e0d008bbf.jpg',\n",
    "'41375ecb2f0390f4328cb1c9a94179.jpg',\n",
    "'baf7ca6c847404d9962ed81260c5c7.jpg',\n",
    "'a1f6ede2ad8d82eeaf59b2dc022da8.jpg',\n",
    "'28576c4dc0ff8c7082b63e6da72442.jpg',\n",
    "'96c179f7e57d9e6204bde75aac9778.jpg',\n",
    "'316777dee32535be262f63de39ca2d.jpg',\n",
    "'b8f00314e9c80fc3d2a609adb41e63.jpg',\n",
    "'f347fafdc58e6081b56ab63008dcfc.jpg',\n",
    "'2869f77b076470b28b5f1b26b9a8df.jpg',\n",
    "'665eed70d66d36754e1f4ff3688e6c.jpg',\n",
    "'f1f9b766b7eff4d6de3792a89184fd.jpg',\n",
    "'c91f4f418ead50690954cf487bf877.jpg',\n",
    "'b2824f7190be843397ef4e2cd5cbdf.jpg',\n",
    "'1e21d02ee9d25d2318964fd4bae782.jpg',\n",
    "'c9819a80d876f2b4f9464a067eb65a.jpg',\n",
    "'fc673285d41e0ef79c9bd8c887565c.jpg',\n",
    "'32fcc238f33bb7165f3fa86c17620d.jpg',\n",
    "'76b8e63b273ab668dfcef2805d92c5.jpg',\n",
    "'10642681aebe3a3312d4fe3f6f4f1f.jpg',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953f4b05-a9ac-4818-a2ad-2798aafacaae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6882a4f2-2e6d-43ec-bb3b-0fd36f94c0b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for filename in fix_30_list:\n",
    "    if f'images/train/{filename}' in train:\n",
    "        filename = filename.split('.')[0]\n",
    "        print(filename)\n",
    "        img_path = f'{path}\\\\train\\\\images\\\\{filename}.jpg'\n",
    "        labels_path = f'{path}\\\\train\\\\labels\\\\{filename}.txt'\n",
    "    else:\n",
    "        filename = filename.split('.')[0]\n",
    "        print(filename)\n",
    "        img_path = f'{path}\\\\val\\\\images\\\\{filename}.jpg'\n",
    "        labels_path = f'{path}\\\\val\\\\labels\\\\{filename}.txt'\n",
    "        \n",
    "    \n",
    "    image = Image.open(img_path)\n",
    "    with open(labels_path, 'r') as file:\n",
    "        labels = file.readlines()\n",
    "    \n",
    "    \n",
    "    annotation_file = labels_path\n",
    "    with open(annotation_file, \"r\") as file:\n",
    "        annotation_list = file.read().split(\"\\n\")[:-1]\n",
    "        annotation_list = [x.split(\" \") for x in annotation_list]\n",
    "        annotation_list = [[float(y) for y in x ] for x in annotation_list]\n",
    "        \n",
    "    # arr_labels = np.array([b_list]).reshape(len(b_list), 5)\n",
    "    #Plot the Bounding Box\n",
    "    plot_bounding_box(image, annotation_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099780c7-ff61-43e3-8496-87d65d69f788",
   "metadata": {},
   "outputs": [],
   "source": [
    "# it is decent, but some labels could be corrected in the future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c54ad3e-95e8-4e0a-b9db-344744100c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames_with_3_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93bdead7-ae72-46e3-8588-298f7977d41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames_with_23_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43aada10-361f-479a-9c6a-bae51cb5f2ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
